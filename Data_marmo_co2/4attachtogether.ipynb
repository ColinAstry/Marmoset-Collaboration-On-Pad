{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#change folder path, marmoset' ID and and expriments' name (bottom) before running\n",
    "########################################################################################\n",
    "# Set the directory path\n",
    "folder_path = r\"D:\\Research\\MarmoCo2\\Data\\ToProcess_Exp\"\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "file_list = os.listdir(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the max t0 of each day and accumulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max t0 for 100: 4408.581\n",
      "Max t0 for 101: 4326.399\n",
      "Accumulated max t0 for 100: 4408.581\n",
      "Accumulated max t0 for 101: 8734.98\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the maximum t0 for each date\n",
    "max_t0_dict = {}\n",
    "\n",
    "# Initialize a dictionary to store the accumulated max t0 for each date\n",
    "accumulated_max_t0 = {}\n",
    "\n",
    "# Get a list of all Excel files in the folder\n",
    "excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "\n",
    "# Sort the files by date\n",
    "excel_files.sort(key=lambda f: f[:3])\n",
    "\n",
    "# First pass: calculate the maximum t0 for each date without considering 'exp' rows\n",
    "for filename in excel_files:\n",
    "    date = filename[:3]\n",
    "    df = pd.read_excel(os.path.join(folder_path, filename))\n",
    "    df_filtered = df[df['note'] != 'exp']  # filter out rows with 'exp' in 'note' column\n",
    "    #check if there is any negative value in t0\n",
    "    if df_filtered['t0'].lt(0).any():\n",
    "        print(f\"Warning: Negative value in t0 for {filename}\")\n",
    "    max_t0 = df_filtered['t0'].max()\n",
    "    if date in max_t0_dict:\n",
    "        max_t0_dict[date] = max(max_t0_dict[date], max_t0)\n",
    "    else:\n",
    "        max_t0_dict[date] = max_t0\n",
    "\n",
    "#print the max t0 for each date\n",
    "for date, max_t0 in max_t0_dict.items():\n",
    "    print(f\"Max t0 for {date}: {max_t0}\")\n",
    "\n",
    "# Second pass: calculate the accumulated max t0 for each date\n",
    "previous_date = None\n",
    "for date in sorted(max_t0_dict.keys()):\n",
    "    if previous_date is not None:\n",
    "        accumulated_max_t0[date] = accumulated_max_t0[previous_date] + max_t0_dict[date]\n",
    "    else:\n",
    "        accumulated_max_t0[date] = max_t0_dict[date]\n",
    "    previous_date = date\n",
    "\n",
    "#print(accumulated_max_t0)\n",
    "# Print the accumulated max t0 for each date\n",
    "for date, max_t0 in accumulated_max_t0.items():\n",
    "    print(f\"Accumulated max t0 for {date}: {max_t0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################\n",
    "# Filter the files that contain \".xlsx\" in their name\n",
    "excel_files = [file for file in file_list if \".xlsx\" in file]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Initialize a variable to store the accumulated \"t0\" value\n",
    "accumulated_t0 = 0\n",
    "\n",
    "# Iterate over the Excel files and sheets\n",
    "for file in excel_files:\n",
    "    # Skip temporary files created by Excel\n",
    "    if file.startswith('~$'):\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Iterate over the sheets in each Excel file\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        # Read the sheet into a DataFrame\n",
    "        df = xls.parse(sheet_name)\n",
    "\n",
    "        # Extract date and ID from the file name\n",
    "        date = file[:4]\n",
    "        id = file[5:8]\n",
    "        \n",
    "        # Add columns with the date and ID\n",
    "        df['Date'] = date\n",
    "        df['ID'] = id\n",
    "\n",
    "        # Neglect rows with \"exp\" in the \"note\" column or \"t0\" value less than 0\n",
    "        df = df[(df['note'] != 'exp') & (df['t0'] >= 0)]\n",
    "\n",
    "        # Accumulate the \"t0\" value\n",
    "        df['t0'] += accumulated_t0\n",
    "\n",
    "        # Update the accumulated \"t0\" value\n",
    "        accumulated_t0 = df['t0'].iloc[-1]\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the common columns across all dataframes\n",
    "common_columns = set(dataframes[0].columns)\n",
    "for df in dataframes[1:]:\n",
    "    common_columns.intersection_update(df.columns)\n",
    "\n",
    "# Convert the set to a list\n",
    "common_columns = list(common_columns)\n",
    "\n",
    "# Concatenate the dataframes by aligning common columns\n",
    "combined_df = pd.concat([df.loc[:, common_columns] for df in dataframes], axis=0)\n",
    "\n",
    "# Define the order of columns\n",
    "column_order = ['ID', 'Date', 'button', 'positionLeft', 'positionTop', 'positionLeftw', 'positionTopw', 't0', 'note', 'time', 'location_x', 'location_y', 'finger']\n",
    "\n",
    "# Get the list of other columns that were not included in column_order\n",
    "other_columns = [col for col in combined_df.columns if col not in column_order]\n",
    "\n",
    "# Combine column_order and other_columns\n",
    "new_order = column_order + other_columns\n",
    "\n",
    "# Reorder the columns of the combined dataframe\n",
    "combined_df = combined_df.reindex(columns=new_order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined sheets saved to: D:\\Research\\MarmoCo2\\Data\\ToProcess_Exp\\analysis\\xlsExp1_20241017.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Write the combined DataFrame to a new Excel file\n",
    "# Define the output directory\n",
    "output_dir = os.path.join(folder_path, \"analysis\")\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "##############################################################################################\n",
    "output_file = os.path.join(folder_path, \"analysis\",f\"{id}Exp1_{current_date}.xlsx\")\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Combined sheets saved to:\", output_file)\n",
    "\n",
    "\n",
    "\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
